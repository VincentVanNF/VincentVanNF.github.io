<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Machine Learning and Deep Learning | VincentVan</title><meta name="keywords" content="ML DL"><meta name="author" content="VincentVan,3080167665@qq.com"><meta name="copyright" content="VincentVan"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="机器学习，深度学习基础知识。">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning and Deep Learning">
<meta property="og:url" content="https://vincentvannf.github.io/2022/07/31/ML/index.html">
<meta property="og:site_name" content="VincentVan">
<meta property="og:description" content="机器学习，深度学习基础知识。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://vincentvannf.github.io/img/ML.jpg">
<meta property="article:published_time" content="2022-07-31T14:50:00.000Z">
<meta property="article:modified_time" content="2022-09-02T16:40:28.536Z">
<meta property="article:author" content="VincentVan">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="Deep Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://vincentvannf.github.io/img/ML.jpg"><link rel="shortcut icon" href="/img/avatar.jpg"><link rel="canonical" href="https://vincentvannf.github.io/2022/07/31/ML/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//www.google-analytics.com" crossorigin=""/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//www.clarity.ms"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="SMp-WCh2-15NoyvdKD57wvY3dGBCraogGZOhwy_h9Qk"/><meta name="baidu-site-verification" content="code-dq7TNN1IXf"/><meta name="msvalidate.01" content="EAEAB8A5E519B85254994EF46F15A64C"/><link rel="manifest" href="/img/siteicons/manifest.json"/><link rel="apple-touch-icon" sizes="180x180" href="/img/siteicons/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/img/siteicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/img/siteicons/favicon-16x16.png"/><link rel="mask-icon" href="/img/siteicons/safari-pinned-tab.svg" color="#5bbad5"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?6977b44415e5cb320371eaf48031d71d";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script async="async" src="https://www.googletagmanager.com/gtag/js?id=UA-239901416-2"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-239901416-2');
</script><script>(function(c,l,a,r,i,t,y){
    c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
    t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
    y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
})(window, document, "clarity", "script", "dhcmcg78px");</script><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"OI6JNF40NR","apiKey":"c21669e336acb106e29d7212316209df","indexName":"hexo","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":500},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":100,"languages":{"author":"作者: VincentVan","link":"链接: ","source":"来源: VincentVan","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Machine Learning and Deep Learning',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-09-03 00:40:28'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><style type="text/css">.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body{left:-66px!important}.aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover{left:0!important}</style><link rel="stylesheet" href="/css/footer-all-transparent.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-footer-beautify@1.0.0/lib/runtime.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">27</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 目录</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/me"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">VincentVan</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 目录</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 娱乐</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/me"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">Machine Learning and Deep Learning</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-07-31T14:50:00.000Z" title="发表于 2022-07-31 22:50:00">2022-07-31</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-09-02T16:40:28.536Z" title="更新于 2022-09-03 00:40:28">2022-09-03</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/ML/">ML</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">4.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>14分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Machine Learning and Deep Learning"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2022/07/31/ML/#post-comment"><span class="gitalk-comment-count"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div><article class="post-content" id="article-container"><h1>监督机器学习</h1>
<p>样本的值是具体已知的。</p>
<ol>
<li>回归问题：根据数据集预测连续的数值</li>
<li>分类问题：根据数据集预测离散的数值</li>
</ol>
<h1>无监督机器学习</h1>
<p>只有数据集没有任何标签(lable)与数值，自动找出数据的某种结构</p>
<h1>2.线性模型</h1>
<ul>
<li>训练集：给出需要预测的数据集(x(i),y(i))</li>
<li>假设函数：h(x)=θ0+θ1x</li>
<li>代价（损失）函数：<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/09/02/hBsfE4TOD2RJlck.png" alt="image-20220902004822067"></li>
</ul>
<h1>3.梯度下降法</h1>
<ul>
<li>
<p>用于<strong>最小化</strong>损失函数J，求解目标函数系数。局部最低点</p>
</li>
<li>
<p>梯度：目标函数的等高线图 增长最快的方向，是一个向量。</p>
</li>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/09/02/aNOrPltv8ywIf5c.png" alt="image-20220902004804725"></p>
</li>
<li>
<p>初始化θ0，θ1，通常为0。</p>
</li>
<li>
<p>需要同步更新θ1，θ0</p>
</li>
<li>
<p>α：学习效率，梯度下降更新参数的速率</p>
</li>
<li>
<p>由于J需要整个训练集的样本，因此每次梯度下降需要遍历整个样本</p>
</li>
<li>
<p>二元线性回归函数各个系数的偏导：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/3SN4zWlecFupCiy.png" alt="image-20220731182224947"></p>
<ul>
<li>
<p>线性函数梯度下降公式：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/dw2VUr3ELTIlAJS.png" alt="image-20220731191141563"></p>
</li>
<li>
<p>线性方程使用矩阵表示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/HelBxgGLCjYRdaE.png" alt="image-20220731191342060"></p>
<ul>
<li>
<p>X * A = Y；</p>
</li>
<li>
<p>X: 行为不同维度的影响因子，每一行第一个通常为1，即常数项因子。列为数据组数。</p>
</li>
<li>
<p>A：系数矩阵：同一列为一组对应因子前的系数。</p>
</li>
<li>
<p>矩阵求逆：AA* = |A|I，A*为伴随矩阵：每个元素的<strong>代数余子式</strong> 构成的矩阵的<strong>转置</strong>。</p>
</li>
<li>
<p>代数余子式：M(i,j) = (-1）^(i + j)  * |划掉所在行，所在列剩余矩阵。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>4.多功能线性回归</h1>
<h2 id="4-1多特征">4.1多特征</h2>
<ul>
<li>
<p>n：特征维度</p>
</li>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/P63EsBpgRTfke8W.png" alt="image-20220731191520778"></p>
</li>
<li>
<p>用矩阵乘法来表示hypothesis formula：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/xKzaotfNOHGJE3M.png" alt="image-20220731191541605"></p>
</li>
</ul>
<h2 id="4-2多元梯度下降">4.2多元梯度下降</h2>
<ul>
<li>
<p>多元损失函数J(θ)：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/HOpz5og8tnYI7lZ.png" alt="image-20220731191737631"></p>
</li>
<li>
<p>梯度下降中的偏导项：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/yMdo1BCIKnwT6qx.png" alt="image-20220731191800473"></p>
</li>
</ul>
<h2 id="4-3特征缩放">4.3特征缩放</h2>
<ul>
<li>
<p>当多个特征的范围一致时：梯度下降速度块：</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/09/02/CRNoUDvZKV2SJ4T.png" alt="4fmSWn.png"></li>
</ul>
</li>
<li>
<p>不一致时：速度慢。</p>
<ul>
<li>
<p>假设hypothesis有两个参数：θ1&gt;&gt;θ2 。损失函数的对应的等值(高）线:</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/09/02/dvJqV4lhEP2A3fF.png" alt="4feUqU.png"></p>
</li>
<li>
<p>根据梯度公式：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/09/02/tjqohn8rscaZvmb.png" alt="4fVTkd.png"></p>
</li>
<li>
<p>范围越大的哪个特质值，梯度中对应参数参数值越大。</p>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>通常特征缩放：将特征范围缩放在：-1&lt;= x &lt;= 1</p>
</li>
<li>
<p>常用方法：均值归一化：</p>
<ul>
<li>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">{</mo><mtable rowspacing="0.36em" columnalign="left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>均值归一化:</mtext><mfrac><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><mi>m</mi><mi>i</mi><mi>n</mi></mrow><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo>−</mo><mi>m</mi><mi>i</mi><mi>n</mi></mrow></mfrac><mi mathvariant="normal">/</mi><mfrac><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mi>u</mi><mi>i</mi></msub></mrow><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo>−</mo><mi>m</mi><mi>i</mi><mi>n</mi></mrow></mfrac></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>标准化:</mtext><mfrac><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mi>u</mi><mi>i</mi></msub></mrow><msub><mi>S</mi><mi>i</mi></msub></mfrac></mrow></mstyle></mtd></mtr></mtable></mrow><annotation encoding="application/x-tex">\begin{cases}\text{均值归一化:} \frac{x_i-min}{max - min} / \frac{x_i-u_i}{max- min} \\ \text{标准化:} \frac{x_i - u_i}{S_i}\end{cases}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6965em;"><span style="top:-3.6965em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord cjk_fallback">均值归一化</span><span class="mord">:</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8718em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ma</span><span class="mord mathnormal mtight">x</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">min</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4101em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">min</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord">/</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8184em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ma</span><span class="mord mathnormal mtight">x</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">min</span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4101em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4033em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-2.2565em;"><span class="pstrut" style="height:3.008em;"></span><span class="mord"><span class="mord text"><span class="mord cjk_fallback">标准化</span><span class="mord">:</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8184em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.0576em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.4101em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1966em;"><span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/jAKH9FXCUgGudTr.png" alt="image-20220731191830717"></p>
</li>
</ul>
</li>
</ul>
<h2 id="4-4学习率：">4.4学习率：</h2>
<ul>
<li>学习率过大：反复横跳，不收敛。</li>
<li>小：梯度下降速度慢。</li>
<li>通常画出损失函数 J(θ) 与梯度下降递归次数的函数图像。应该是个单调递减图像。</li>
</ul>
<h2 id="4-5特征与多项式回归">4.5特征与多项式回归</h2>
<ul>
<li>多项式可以将高次项换元成一次项 变成线性回归。</li>
</ul>
<h2 id="4-6正规方程">4.6正规方程</h2>
<ul>
<li>
<p>给定一组样本数据 与 预期结果，用矩阵表示为：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/gzJcEh4ano6lLqO.png" alt="image-20220731192145849"></p>
<ul>
<li>
<p>正规方程：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/xU1DB4YKpyHTFAk.png" alt="image-20220731192226728"></p>
</li>
<li>
<p>证明过程：</p>
</li>
<li>
<p>正规方程与梯度下降：</p>
<ul>
<li>梯度下降：
<ul>
<li>需要选择学习效率α，需要迭代</li>
<li>n很大时仍然可以很好的运行</li>
</ul>
</li>
<li>正规方程
<ul>
<li>不需要选择学习效率，也不需要迭代</li>
<li>n很大时不能很好的运行，计算矩阵的逆开销很大O(N^3)</li>
<li>线性回归模型中，数据特征少时可以替代梯度下降</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>正规方程矩阵不可逆时（奇异矩阵\退化矩阵）：</p>
<ul>
<li>可能是有两列（不同特征）是线性相关的，那么就删除一个特征。</li>
<li>可能是特征值过多，则删除一些特征值。</li>
</ul>
</li>
</ul>
<h1>5.分类：逻辑回归算法</h1>
<h2 id="5-1-二分类问题">5.1 二分类问题</h2>
<ul>
<li>
<p>logical function/sigmod function:</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/1xHSGrWkfYK3zuB.png" alt="image-20220731192258473"></p>
<ul>
<li>输出：二分类：
<ul>
<li>概率</li>
<li>P( Y = 0 | x;θ) = 1 - P (y = 1| x;θ)</li>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/21/gEnGO8UaDwT4huo.png" alt="image-20220621180150306"></li>
</ul>
</li>
</ul>
</li>
<li>
<p>决定边界</p>
<ul>
<li>θX</li>
<li>θX &gt;=0,out&gt;0.5</li>
<li>θX&lt;0,out&lt;0.5</li>
<li>决策边界不是由数据集决定，给定θ即确定一个决策边界，数据集不断地拟合决策边界。</li>
</ul>
</li>
<li>
<p>代价函数</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/aADH2gpScxYLtm8.png" alt="image-20220731192402130"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/ad5jnCymbG8HPf9.png" alt="image-20220731192424938"></p>
<ul>
<li>
<p>由于sigmod为非线性函数，代价函数不是凸函数，梯度下降会找到局部最优解。</p>
</li>
<li>
<p>采用新cost_func</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/LTBJxKXkUIq13rC.png" alt="image-20220731192456474"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/rWFij2OcZPlHdh1.png" alt="image-20220731192516936"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/3WkYDL5jcRmBlUf.png" alt="image-20220731192545783"></p>
</li>
<li>
<p>连续性cost_function：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/BvyP3aSUo8x6Hk1.png" alt="image-20220731192607714"></p>
<ul>
<li>
<p>极大似然估计法得出地cost_func</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/a814HhctLBkpMq5.png" alt="image-20220731192642360"></p>
</li>
</ul>
</li>
<li>
<p>梯度下降算法：拟合θ</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/gjhf7Omq6zPyb4T.png" alt="image-20220731192701175"></p>
</li>
<li>
<p>其他算法：</p>
<ul>
<li>Conjugate gradient</li>
<li>BFGS</li>
<li>L-BFGS</li>
<li>不需要手动选择学习效率</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="5-2-多分类问题">5.2 多分类问题</h2>
<h3 id="5-2-1一对多">5.2.1一对多</h3>
<ul>
<li>
<p>使用多个二分类器函数:拟合出多个决定边界</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/iqmbZXL5cdV3e7H.png" alt="image-20220731192718975"></p>
</li>
<li>
<p>预测：x特征值输入每个分类器，得到的最大值：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/FX72gR5WIospAZa.png" alt="image-20220731192742746"></p>
</li>
</ul>
<h2 id="5-3-过拟合">5.3 过拟合</h2>
<h3 id="5-3-1线性回归正则化">5.3.1线性回归正则化</h3>
<ul>
<li>
<p>特征值过多，数据集过少</p>
</li>
<li>
<p>解决：</p>
<ul>
<li>
<p>减少特征向量</p>
</li>
<li>
<p><strong>正则化</strong> （ 减少规模/或者参数θ的大小）</p>
</li>
<li>
<p>正则化方程</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/VnLfDo9wsMTEbQJ.png" alt="image-20220731192813498"></p>
<ul>
<li>前一半为优化参数目标损失函数，后一半为<strong>正则化参数</strong>参数平方之和，会使得每个θ都适当减小。</li>
<li>正则化参数太大，使得惩罚系数过大，θ1到θj都趋近于0，而退化成水平直线。</li>
</ul>
</li>
<li>
<p>正则化后的梯度下降:</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/nywPH2SUsuCJlbR.png" alt="image-20220731192833083"></p>
</li>
<li>
<p>正规方程使用正则化:</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/wJS5EeiHkUd7Zmb.png" alt="image-20220731192849520"></p>
<ul>
<li>同时解决了X^T*X 矩阵不可逆的情况。(m &lt; n)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="5-3-2-logical回归正则化">5.3.2 logical回归正则化</h3>
<ul>
<li>
<p>同理线性回归的损失函数：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/mHBxPWv13d5gCaT.png" alt="image-20220731192910255"></p>
<ul>
<li>
<p>梯度下降：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/H5ntSb3YVi4pvzc.png" alt="image-20220731192934079"></p>
</li>
<li>
<p>高级优化函数使用正则化:</p>
<ul>
<li>
<p>自定义costFunction函数计算损失，和梯度：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/gHMvO1yPA3SQdxm.png" alt="image-20220731192951935"></p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>6 神经网络</h1>
<h2 id="6-1-模型展示">6.1 模型展示</h2>
<ul>
<li>
<p>神经元<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/gPKvoeMz5aysuLn.png" alt="image-20220731193130037"></p>
</li>
<li>
<p>神经网络</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/DuEV9xSv8UiZ2e7.png" alt="image-20220731193507938"></p>
<ul>
<li>输入层（Input layer):</li>
<li>神经元,激活层(activation function:sigmoiod function)</li>
<li>隐藏层(hidden layer)</li>
<li>输出层 (out layer)</li>
<li>权重</li>
</ul>
</li>
<li>
<p>计算过程:</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/aUrhEXoDiKpWNc2.png" alt="image-20220731195031478"></p>
<ul>
<li>
<p>说明：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>S</mi><mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>:</mo><mtext>第</mtext><mi>i</mi><mo>+</mo><mn>1</mn><mtext>层神经元个数</mtext></mrow><annotation encoding="application/x-tex">S_{i+1}: 第i+1层神经元个数
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8917em;vertical-align:-0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2083em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord cjk_fallback">第</span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord">1</span><span class="mord cjk_fallback">层神经元个数</span></span></span></span></span></p>
<p>​</p>
<ul>
<li>θ矩阵：j层到j+1层的权重矩阵，用于计算下一层的输入，维度为：S(j+1) * （Sj + 1):
<ul>
<li>Sj+1行θ</li>
<li>每一行Sj + 1个 权重参数</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="6-2-模型展示">6.2 模型展示</h2>
<ul>
<li>
<p>前向传播</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/BztFq2uQc8syPYl.png" alt="image-20220731202832626"></p>
</li>
<li>
<p>使用隐藏层的输出作为 logistic regression 的输入特征：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/3DcPXeLYQ5aEnds.png" alt="image-20220731202912615"></p>
</li>
<li>
<p>神经网络架构：神经元的连接方式</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/bUXKh1ptPi8ECVG.png" alt="image-20220731202934630"></p>
</li>
</ul>
<h2 id="6-3例子与直觉解释">6.3例子与直觉解释</h2>
<ul>
<li>
<p>神经网络用于学习复杂的非线性假设模型</p>
</li>
<li>
<p>AND 逻辑函数拟合：</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/21/wKVnzUW4csaORFx.png" alt="image-20220621225415638"></li>
</ul>
</li>
<li>
<p>OR 逻辑拟合</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/21/mrQhWcxkYVapROJ.png" alt="image-20220621225621714"></li>
</ul>
</li>
<li>
<p>NOT 逻辑拟合</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/21/cJGPjMhlz1qnXp8.png" alt="image-20220621225825038"></li>
</ul>
</li>
<li>
<p>XNOR(同或)</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/21/UduhCjvDOsarKP1.png" alt="image-20220621230404176"></li>
</ul>
</li>
</ul>
<h2 id="6-4多元分类">6.4多元分类</h2>
<ul>
<li>一对多：
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/21/MsTJorCPu9BkIW1.png" alt="image-20220621231254723"></li>
</ul>
</li>
</ul>
<h1>7 神经网络原理</h1>
<h2 id="7-1-代价函数">7.1 代价函数</h2>
<ul>
<li>
<p>神经网络代价函数</p>
</li>
<li>
<p>分类模型</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/21/MxogjTefswFvcOJ.png" alt="image-20220621232152230"></p>
</li>
<li>
<p>L :神经网络层数</p>
</li>
<li>
<p>S_l: l层神经元个数，不含偏置单元</p>
</li>
</ul>
</li>
<li>
<p>损失函数</p>
<ul>
<li>
<p>逻辑回归损失函数</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/21/Hlx9qYcRpmnbFMr.png" alt="image-20220621232656123"></li>
</ul>
</li>
<li>
<p>神经网络损失函数：逻辑回归一般表达：</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/DQ5NpWX6a2cI1YG.png" alt="image-20220622003843433"></p>
</li>
<li>
<p>每一类的交叉损失函数 求和“1–K</p>
</li>
<li>
<p>正则参数：j：θ矩阵行数，i：θ矩阵列数，未算偏置参数</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="7-2-反向传播算法">7.2 反向传播算法</h2>
<ul>
<li>
<p>损失函数</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/uf1xiImMdA7oOka.png" alt="image-20220622150602922"></li>
</ul>
</li>
<li>
<p>前向传播</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/AqLS6vNzTusGKUE.png" alt="image-20220622151323543"></li>
</ul>
</li>
<li>
<p>反向传播：</p>
<ul>
<li>
<p>误差 ：定义：误差可根据反向传播获得<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/J7Ay1N3iM8q6UnH.png" alt="image-20220622165426517"></p>
</li>
<li>
<p>根据误差可求权重偏导：</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/zpVdofgcFjyhSmP.png" alt="image-20220622182633693"></p>
</li>
<li>
<p>详细解释：<a target="_blank" rel="noopener" href="https://blog.csdn.net/TianJingDeng/article/details/103688858">吴恩达|如何理解神经网络误差反向传播算法_Tianjin Deng的博客-CSDN博客</a></p>
</li>
</ul>
</li>
<li>
<p>”误差“计算：根据链式法则：详细解释：<a target="_blank" rel="noopener" href="https://blog.csdn.net/xuan_liu123/article/details/83660316"> 吴恩达机器学习视频–神经网络反向传播算法公式推导_xuan_liu123的博客-CSDN博客_吴恩达反向传播</a></p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/Iln2WxTXPd1y86i.png" alt="image-20220622170447872"></li>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/Bpfhz8GgxDsRAoW.png" alt="image-20220622170026465">
<ul>
<li>点乘：矩阵同位置元素相乘</li>
</ul>
</li>
</ul>
</li>
<li>
<p>多样本：上标i 与下标i不同意义：</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/lsxD4VtGMd6wFWY.png" alt="image-20220622184100491"></p>
</li>
<li>
<p>向量化：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/GCzyFnc82vkLwbe.png" alt="image-20220622184355625"></p>
<ul>
<li>Δ与Θ矩阵同行列，行：L+1层神经元个数；列：L层神经元个数</li>
<li>最终的梯度：<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/tzGj97eWvmPZ1sn.png" alt="image-20220622185319991">
<ul>
<li>j=0,对应的每层的偏置项，没有正则项</li>
</ul>
</li>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/S9YhdjnziOLmkGs.png" alt="image-20220622185429737"></li>
</ul>
</li>
</ul>
</li>
<li>
<p>总结：</p>
<ul>
<li>
<p>公式一：<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/NFVHvberdmAkSO1.png" alt="image-20220622185543471"></p>
</li>
<li>
<p>公式二：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/3dT4iX9YEFRWSgP.png" alt="image-20220622170447872"></p>
<ul>
<li>
<p>公式三：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/9AEogGM2DLUveNn.png" alt="image-20220622182633693"></p>
</li>
</ul>
</li>
<li>
<p>根据这三个公式，可以完成反向多样本反向传播算法：计算出每个θ的偏导项</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/h9RGXzvFPnVpr63.png" alt="image-20220622185905071"></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="7-3-梯度检测">7.3 梯度检测</h2>
<ul>
<li>
<p>梯度的近似值计算 并与梯度进行比较</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/KtzDT49C3Mk2dwp.png" alt="image-20220622221659694"></p>
</li>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/LVZrvtdOYwsPfkp.png" alt="image-20220622221943076"></p>
</li>
<li>
<p>训练时关闭 梯度检测 方法：降低算法效率。</p>
</li>
</ul>
</li>
</ul>
<h2 id="7-4-随机初始化">7.4 随机初始化</h2>
<ul>
<li>
<p>初始化全为0：</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/atd4GpU7TqoXh1l.png" alt="image-20220622223443587"></p>
</li>
<li>
<p>所有的输入输出值都为相同的值和函数</p>
</li>
</ul>
</li>
</ul>
<h2 id="7-5-总结">7.5 总结</h2>
<ul>
<li>
<p>神经网络架构：神经元之间的连接方式。</p>
<ul>
<li>输入：特征值的维度</li>
<li>输出：分类的个数</li>
<li>合理的默认架构：一个隐藏层，或者多个隐藏层的神经元个数相等</li>
</ul>
</li>
<li>
<p>训练神经网络步骤：</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/T1ogSziFJmPUWnw.png" alt="image-20220622224619915"></p>
</li>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/22/mRjybUaFCJgGEuW.png" alt="image-20220622225048877"></p>
</li>
<li>
<p>搭建神经网络并随机初始化参数值</p>
</li>
<li>
<p>实现前向传播计算每层输入与输出值</p>
</li>
<li>
<p>实现损失函数</p>
</li>
<li>
<p>实现反向传播计算每个参数偏导项</p>
</li>
<li>
<p>使用梯度检测 检测梯度近似值是否符合要求，训练前关闭梯度检测</p>
</li>
<li>
<p>使用梯度下降或者其他优化算法 优化损失函数。</p>
</li>
</ul>
</li>
</ul>
<h1>8 机器学习算法诊断</h1>
<h2 id="8-1-评估假设">8.1 评估假设</h2>
<ul>
<li>防止过拟合：
<ul>
<li>正则化</li>
<li>减少多余特征</li>
<li>划分数据集，7：3 训练集+测试集</li>
</ul>
</li>
<li>使用测试数据集 计算测试误差</li>
</ul>
<h2 id="8-2-模型-特征选择，训练，验证，测试数据集">8.2 模型/特征选择，训练，验证，测试数据集</h2>
<ul>
<li>增强模型泛化能力
<ul>
<li>将数据集划分为 训练集 验证集 测试集6 ： 2 ： 2</li>
<li>训练集误差， 验证集误差，测试集误差</li>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/CAdBKXMprFfIL9j.png" alt="image-20220623160950194"></li>
</ul>
</li>
</ul>
<h2 id="8-3-诊断偏差与方差">8.3 诊断偏差与方差</h2>
<ul>
<li>
<p>验证集误差与训练集误差 图：</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/1YVMwtX9jdcgzuZ.png" alt="image-20220623155043956"></p>
</li>
<li>
<p>高偏差问题：左边，欠拟合，训练集验证集误差都很大</p>
</li>
<li>
<p>高方差问题：右边，过拟合，训练姐误差小，验证集误差大</p>
</li>
</ul>
</li>
</ul>
<h2 id="8-4-正则化与偏差，方差">8.4 正则化与偏差，方差</h2>
<ul>
<li>
<p>正则化参数过大：</p>
<ul>
<li>欠拟合，训练数据集和验证集误差都大，偏差问题</li>
</ul>
</li>
<li>
<p>正则化参数刚好</p>
</li>
<li>
<p>正则化参数过小</p>
<ul>
<li>过拟合，训练集误差小验证集误差大，方差问题。</li>
</ul>
</li>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/FOx1izXEk6jDAHy.png" alt="image-20220623155753988"></p>
</li>
<li>
<p>如何选择正则化参数</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/aD2TUm4xtAcsuy1.png" alt="image-20220623160758213"></li>
</ul>
</li>
<li>
<p>正则化参数图</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/6FDOunY7K1l2wWy.png" alt="image-20220623161155797"></li>
</ul>
</li>
</ul>
<h2 id="8-5-学习曲线">8.5 学习曲线</h2>
<ul>
<li>
<p>学习曲线：检验算法是否正确，是否存在偏差，方差问题</p>
<ul>
<li>y轴：误差</li>
<li>x轴：数据集大小</li>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/mLz1PxbahnvQ3G4.png" alt="image-20220623161946197"></li>
</ul>
</li>
<li>
<p>高偏差：high bias</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/kKUL7j8OzaqxnYB.png" alt="image-20220623162143732"></li>
</ul>
</li>
<li>
<p>高方差：high variance</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/fvyeiK5kFNaw1DH.png" alt="image-20220623162429516"></li>
</ul>
</li>
<li>
<p>选择优化方法：</p>
<ul>
<li>
<p>过拟合/高方差问题：获取更多数据集，减少特征数量，正则化，提高正则化参数</p>
</li>
<li>
<p>欠拟合/高偏差问题：获取更多特征，添加其他多项式特征，减小正则化参数</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/RnUTzqgBCOJihZu.png" alt="image-20220623164345942"></p>
</li>
</ul>
</li>
</ul>
<h1>9 机器学习系统设计思想</h1>
<h2 id="9-1不对称分类误差评估">9.1不对称分类误差评估</h2>
<ul>
<li>偏斜类问题：数据集中其中一类的数据过多或过少
<ul>
<li>偏斜类问题 需要一种新的评估参数：查准率/召回率(Precision/Recall):</li>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/MCdasbKH4jpZ9hl.png" alt="image-20220623212832555"></li>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/Rh7y9IdDrSeWHNf.png" alt="image-20220623211841087">-
<ul>
<li>Precision查准率：某一类准确预测数/预测为该类的总数</li>
<li>Recall 召回率：某一类准确预测数/该类的总数</li>
</ul>
</li>
<li>F score：
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/3QdIa6Thb847OZ2.png" alt="image-20220623215133504"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>10 支持向量机 SVM</h1>
<h2 id="10-1优化目标">10.1优化目标</h2>
<ul>
<li>
<p>损失函数：对逻辑回归损失函数做一点小修改</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/mTMyov7VwsCPLB5.png" alt="image-20220623221914469"></p>
</li>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/9vLGUeROEWdZJnV.png" alt="image-20220623222612210"></p>
<ul>
<li>参数C  与正则化参数 λ相同的作用</li>
</ul>
</li>
<li>
<p>SVM 不输出概率 而是直接进行分类输出</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/YvPHMbdoZFWtRTw.png" alt="image-20220623222909532"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="10-2-大间距分类器">10.2 大间距分类器</h2>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/H9yBf5ZlKVXQuJY.png" alt="image-20220623223507526"></p>
<ul>
<li>对比于逻辑回归，当y=1时，z&gt;=1时，才能预测为1</li>
<li>y=0时,z&lt;=-1时才能预测为0</li>
</ul>
</li>
<li>
<p>SVM 决策边界：</p>
<ul>
<li>C十分大的情况下 拟合出来的决策边界：存在一个SVM间距</li>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/DgEJxF9hkdirW81.png" alt="image-20220623224709399"></li>
</ul>
</li>
<li>
<p>数学原理</p>
<ul>
<li>
<p>假设只有两个特征，θ0=0</p>
</li>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/23/XszNTMq2ixyFA3g.png" alt="image-20220623231742805"></p>
</li>
<li>
<p>θX=0为决策边界，因此θ向量与决策边界正交</p>
</li>
<li>
<p>此时X向量向θ向量投影会非常的小，满徐限制条件则θ向量的模 需要十分大，此时J损失函数误差大，因此此 决策边界不行</p>
</li>
</ul>
</li>
</ul>
<h2 id="10-3-核函数">10.3 核函数</h2>
<ul>
<li>
<p>相似度函数：高斯核函数：</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/1spmwPjanzcYoUg.png" alt="image-20220624121334715"></p>
</li>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/Cc3LM1yfqYd5m2e.png" alt="image-20220624121544524"></p>
</li>
<li>
<p>核函数图</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/TAg5hOUza6uCLfe.png" alt="image-20220624122231479"></li>
</ul>
</li>
<li>
<p>核函数与决策边界：</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/cDtKlgxEG8CpYZf.png" alt="image-20220624122745260"></li>
</ul>
</li>
</ul>
</li>
<li>
<p>标记点 landmark：</p>
<ul>
<li>
<p>直接选取样本点为landmark：</p>
</li>
<li>
<p>将样本点特征值映射到新的特征空间:维度发生了变化</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/uNvYq9zBhkgpox8.png" alt="image-20220624123425424"></li>
</ul>
</li>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/YSklnv6WNcryERj.png" alt="image-20220624123957492"></p>
</li>
</ul>
</li>
<li>
<p>SVM参数C</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/9onDWyZtvw6IUjY.png" alt="image-20220624124630426"></li>
<li>C大：低偏差，高方差（过拟合）</li>
<li>C小；高偏差，低方差（欠拟合）</li>
</ul>
</li>
<li>
<p>SVM参数 ð</p>
<ul>
<li>大：高偏差，低方差（欠拟合）</li>
<li>小：低偏差，高方差（过拟合）</li>
</ul>
</li>
</ul>
<h2 id="使用SVM">使用SVM</h2>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/BlrPuFUj5zJkV3Q.png" alt="image-20220624151339597"></p>
<ul>
<li>
<p>指定参数C</p>
</li>
<li>
<p>指定核函数</p>
<ul>
<li>线性核函数：初始特征维度n大，数据集m小，使用非线性容易过拟合</li>
<li>高斯核函数：初始特征维度n小，数据集m大
<ul>
<li>提供核函数计算方式：</li>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/BKIHkgf2a5QuEdh.png" alt="image-20220624151653365"></li>
</ul>
</li>
</ul>
</li>
<li>
<p>核函数需满足 莫塞尔定理</p>
<ul>
<li>多项式核函数
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/QocuY75pPZFROed.png" alt="image-20220624152531510"></li>
</ul>
</li>
<li>字符串核函数，卡方核函数，直方核函数</li>
</ul>
</li>
<li>
<p>逻辑回归与SVM</p>
<ul>
<li>特征维度 n &gt;&gt; m
<ul>
<li>线性回归，线性核函数SVM</li>
</ul>
</li>
<li>特征维度 n小，m适中
<ul>
<li>高斯SVM</li>
</ul>
</li>
<li>特征维度n小，m大
<ul>
<li>创建更多特征，使用逻辑回归 并 使用线性核函数SVM</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1>11 无监督学习</h1>
<ul>
<li>数据集没有标签</li>
<li>通过算法找到数据集中的结构：聚类算法</li>
</ul>
<h2 id="11-1-K-Means-聚类算法">11.1 K-Means 聚类算法</h2>
<ul>
<li>
<p>选取聚类中心 (cluster center)</p>
</li>
<li>
<p>首先进行簇分类：根据距离聚类中心的距离对样本进行分类</p>
</li>
<li>
<p>然后进移动聚类中心：计算同一类样本的均值并移动聚类中心到均值</p>
</li>
<li>
<p>重复进行迭代</p>
</li>
<li>
<p>K-Means 算法输入</p>
<ul>
<li></li>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/5uYaZm9MecPCwxb.png" alt="image-20220624182258825"></p>
</li>
<li>
<p>聚类数目：K</p>
</li>
<li>
<p>无标签样本</p>
</li>
</ul>
</li>
<li>
<p>K-Means 算法步骤</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/5sfq8QmgpFE1TZS.png" alt="image-20220624183116788"></li>
</ul>
</li>
</ul>
<h2 id="11-2-优化目标">11.2 优化目标</h2>
<ul>
<li>
<p>优化目标：失真代价函数</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/1lavoY9UiM5SerE.png" alt="image-20220624190502610"></p>
</li>
<li>
<p>使损失函数最小：</p>
<ul>
<li>找到每个样本所属的聚类c参数</li>
<li>找到每个聚类的聚类中心</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="11-3随机初始化">11.3随机初始化</h2>
<ul>
<li>
<p>随机初始化</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/sa8JiY14CerpTdE.png" alt="image-20220624191601458"></p>
</li>
<li>
<p>聚类数小于样本数</p>
</li>
<li>
<p>随机K个训练样本作为 初始化聚类中心</p>
</li>
</ul>
</li>
<li>
<p>局部最优化</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/PBNk4V2onCWf5ea.png" alt="image-20220624192428597"></li>
</ul>
</li>
<li>
<p>防止局部最优解，运行多次随机初始化并寻找最小损失函数解</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/YJRZAMzIWh4Vjk2.png" alt="image-20220624192546671"></li>
</ul>
</li>
</ul>
<h2 id="11-4-选取聚类数量">11.4 选取聚类数量</h2>
<ul>
<li>
<p>肘部法则</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/ujpeg1O3aDV6Tvn.png" alt="image-20220624193126863"></li>
</ul>
</li>
<li>
<p>根据下游目的选择K的数量</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/24/gcMaKfXpDCTexn4.png" alt="image-20220624193704381"></li>
</ul>
</li>
</ul>
<h1>12 降维</h1>
<h2 id="12-1-数据压缩">12.1 数据压缩</h2>
<ul>
<li>
<p>2D-1D:</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/VsQ4FCOubLatryc.png" alt="image-20220624204806772"></li>
</ul>
</li>
<li>
<p>3D - 2D</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/WKHab1urGDYfOwN.png" alt="image-20220624204848595"></li>
</ul>
</li>
</ul>
<h2 id="12-2-主成分析问题规划-PCA">12.2 主成分析问题规划 PCA</h2>
<ul>
<li>
<p>将高维特征 映射到低维 空间</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/AsZwKPuI8cSgl7O.png" alt="image-20220624210626335"></p>
</li>
<li>
<p>寻找K个向量组成的子空间，将n维向量映射到该子空间</p>
</li>
</ul>
</li>
<li>
<p>线性回归与 PCA：误差函数不一样</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/6PKGfFXEYdAHnpc.png" alt="image-20220624210921887"></li>
</ul>
</li>
<li>
<p>PCA算法过程</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/hNLDQpnVZ7zq6fk.png" alt="image-20220624214218051"></p>
</li>
<li>
<p>首先进行特征值的均值归一化/特征缩放</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/iwAtU1SYqykoseN.png" alt="image-20220624214432722"></li>
</ul>
</li>
<li>
<p>然后计算协方差矩阵，并运用奇异值分解计算协方差矩阵获得 前k个向量组成的低维子空间</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/4KF16hWBpidoQJg.png" alt="image-20220624214802496"></li>
</ul>
</li>
<li>
<p>最后计算 映射到低维的向量</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/07/31/vFR3xMWcYQoNrKf.png" alt="image-20220624215021820"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="12-3-压缩重现">12.3 压缩重现</h2>
<ul>
<li>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/s5CiR8gpubZ1mGD.png" alt="image-20220624220438140"></li>
</ul>
</li>
</ul>
<h2 id="12-4如何选择K">12.4如何选择K</h2>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/8Ulnmi1qYP5tGwM.png" alt="image-20220624222503778"></li>
<li>确保该不等式小于等于一个小值：也称作保留了99%方差</li>
<li>如何查看该值是否满足要求，在svd函数中返回的矩阵即可求解，不需要反复计算该值：
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/Glsn8YPER49IbVz.png" alt="image-20220624222800425"></li>
</ul>
</li>
</ul>
<h2 id="12-5-PCA使用建议">12.5 PCA使用建议</h2>
<ul>
<li>
<p>应用：</p>
<ul>
<li>数据降维加快算法效率</li>
<li>数据可视化</li>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/lSPAXCYo4GhkqEN.png" alt="image-20220624224149023"></li>
</ul>
</li>
<li>
<p>PCA不用于 防止过拟合</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/7mvpgS1W64PKrQG.png" alt="image-20220624224235657"></li>
</ul>
</li>
</ul>
<h1>13 异常检测</h1>
<h2 id="13-1-问题动机">13.1 问题动机</h2>
<ul>
<li>
<p>主要用于非监督学习</p>
<ul>
<li>
<p>例子</p>
</li>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/Ck2MiyDd87maItv.png" alt="image-20220625160559316"></p>
</li>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/MLruxbIvHYBNTok.png" alt="image-20220625160734599"></p>
<ul>
<li>用户欺骗行为检测</li>
<li>工业产品制造检测</li>
<li>数据中心集群检测</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="13-2-高斯分布（正态分布）">13.2 高斯分布（正态分布）</h2>
<ul>
<li>
<p>高斯分布：</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/s3FVvyl1dbB9wmQ.png" alt="image-20220625161848085"></li>
</ul>
</li>
<li>
<p>参数估计问题：给定数据集，拟合出数据集的概率分布参数</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/VE9hlK2JMnaz3YZ.png" alt="image-20220625162113860"></li>
</ul>
</li>
</ul>
<h2 id="13-3-异常检测算法">13.3 异常检测算法</h2>
<ul>
<li>
<p>（各个特征独立同分布/不独立也可以），假设概率模型P(x) 为：</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/fjqN49GrRQJYKnV.png" alt="image-20220625163457242"></li>
</ul>
</li>
<li>
<p>算法步骤</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/EopXYP5g4ZNqzan.png" alt="image-20220625164010183"></p>
</li>
<li>
<p>选择特征值</p>
</li>
<li>
<p>计算拟合每个特征的 正态分布 参数并计算总的概率密度函数</p>
</li>
<li>
<p>带入新的数据参数 计算概率值</p>
</li>
</ul>
</li>
</ul>
<h2 id="13-4-评估-异常检测算法">13.4 评估 异常检测算法</h2>
<ul>
<li>
<p>划分数据集</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/1849RuASVaMKw3T.png" alt="image-20220625170632034"></p>
</li>
<li>
<p>训练集：无标签</p>
</li>
<li>
<p>CV 交叉验证集：带标签</p>
</li>
<li>
<p>测试集：带标签</p>
</li>
</ul>
</li>
<li>
<p>评估步骤</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/gTdrbs3Q1kuSWXI.png" alt="image-20220625170712665"></p>
<ul>
<li>计算拟合模型P(x)</li>
<li>在 CV集 和test集 上计算 概率值并检验是否异常</li>
<li>计算画出评估矩阵，计算查准率和召回率 并计算 F-score</li>
</ul>
</li>
</ul>
<h2 id="13-5-异常检测与监督学习">13.5  异常检测与监督学习</h2>
<ul>
<li>异常检测：正样本/负样本 很少</li>
<li>监督学习：正样本与负样本 都很多
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/97duGrX8zTVUO2i.png" alt="image-20220625172433841"></li>
</ul>
</li>
</ul>
<h2 id="13-6-如何-选择-异常检测-特征">13.6 如何 选择 异常检测 特征</h2>
<ul>
<li>
<p>画出数据集中不同特征的直方图</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/SVRToGCElO4tYNA.png" alt="image-20220625173007324"></li>
</ul>
</li>
<li>
<p>误差分析：</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/iqH4YotI8lTMBvh.png" alt="image-20220625173803119"></p>
</li>
<li>
<p>从CV数据集中检查 被误分类的数据，并检查其中的特征，是否包含标志性特征</p>
</li>
</ul>
</li>
</ul>
<h2 id="13-7-多变量高斯分布">13.7 多变量高斯分布</h2>
<ul>
<li>
<p>多变量高斯分布 函数</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/oZtkH8emMvsyUif.png" alt="image-20220625175806454"></p>
</li>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/EQm3tbeJMDvy6xr.png" alt="image-20220625180615656"></p>
</li>
</ul>
</li>
<li>
<p>通过数据集拟合 多元高斯函数 参数：</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/iu3hLGDaQmzA5Zs.png" alt="image-20220625180737514"></li>
</ul>
</li>
<li>
<p>多元高斯分布函数 异常检测算法步骤</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/kiRQIUPjpL53C1f.png" alt="image-20220625181157207"></li>
</ul>
</li>
<li>
<p>普通高斯函数模型与多元高斯函数模型</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/JFlbzEs6wGkC4iu.png" alt="image-20220625182156935"></li>
<li>普通高斯函数时一种特殊情况：多元高斯模型 协方差矩阵非对角线值为0</li>
<li>多元高斯模型可以自动捕获特征之间的关系，普通高斯分布模型需要设置一个新的特征捕获特征间的关联，普通高斯模型计算性能更快</li>
</ul>
</li>
</ul>
<h1>14 推荐算法</h1>
<h2 id="14-1-基于内容的推荐算法">14.1 基于内容的推荐算法</h2>
<ul>
<li>
<p>例子：根据已有用户对不同 电影的评价，拟合出不同用户的 的参数，从而预测用户未看过的电影评价</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/aRYvc3hPQorzO5G.png" alt="image-20220625184808139"></p>
</li>
<li>
<p>假设每个电影有两个特征：浪漫程度和 动作指数</p>
</li>
<li>
<p>参数意义：</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/Gr2SvWLF79aoueE.png" alt="image-20220625184932956"></li>
</ul>
</li>
<li>
<p>优化函数：</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/TNGF6ERwid9KCrz.png" alt="image-20220625185005064"></p>
</li>
<li>
<p>对每个用户j：有一个参数向量θ_j，总的优化目标函数将每个 用户的损失函数相加 并加上正则项</p>
</li>
</ul>
</li>
<li>
<p>计算梯度</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/V1KzaQWjsogCukZ.png" alt="image-20220625185203576"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="14-2-协同过滤">14.2 协同过滤</h2>
<ul>
<li>
<p>先提供参数 θ_j， 拟合出每个电影的特征值 x_i</p>
</li>
<li>
<p>优化目标：</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/RoGhHJBFXA37n1M.png" alt="image-20220625192433632"></p>
</li>
<li>
<p>对于每个电影的特征值 x_i，计算在已知θ_j 下的误差值并求和，再优化</p>
</li>
</ul>
</li>
<li>
<p>协同过滤</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/qltUCRAxNZDnk3W.png" alt="image-20220625192612648"></p>
</li>
<li>
<p>随机初始化θ_j, 拟合出 特征值 x_i，再拟合出 θ_j ,直到收敛</p>
</li>
</ul>
</li>
<li>
<p>将两个优化目标 函数结合在一起：</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/WOwlsr8VMmRBah4.png" alt="image-20220625193301324"></li>
</ul>
</li>
<li>
<p>协同过滤步骤</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/CWvhyZ53JS98ndb.png" alt="image-20220625194347444"></p>
</li>
<li>
<p>随机初始化特征值 向量与 参数向量</p>
</li>
<li>
<p>优化算法 优化协同损失函数</p>
</li>
<li>
<p>对 用户未作评价的电影 根据拟合的 参数θ和电影的特征值进行预测</p>
</li>
</ul>
</li>
</ul>
<h2 id="14-3-协同过滤向量化">14.3 协同过滤向量化</h2>
<ul>
<li>
<p>低秩矩阵分解：</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/kUWIJzyPoFxDnVS.png" alt="image-20220625195313065"></li>
</ul>
</li>
<li>
<p>相似推荐：</p>
<ul>
<li>根据学习到的特征向量，判断两个电影的相似程度：
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/CjiBQ12sabLnGJO.png" alt="image-20220625195826358"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="14-4-均值归一化">14.4 均值归一化</h2>
<ul>
<li>将数据集均值归一化后进行训练：
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/sOSy1w3kgNrfzUB.png" alt="image-20220625200435465"></li>
</ul>
</li>
</ul>
<h1>15 大数据机器学习处理</h1>
<h2 id="15-1-随机梯度下降">15.1 随机梯度下降</h2>
<ul>
<li>
<p>思想：在对数据集进行遍历一次的同时开始 对参数进行拟合优化，而不是需要进行多次遍历数据求和进行梯度下降。</p>
</li>
<li>
<p>步骤</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/DzimTPh1X8lrECU.png" alt="image-20220625202003777"></p>
</li>
<li>
<p>随机打乱数据</p>
</li>
<li>
<p>对每个样本数据集 进行单个梯度下降，进行参数拟合</p>
</li>
</ul>
</li>
</ul>
<h2 id="15-2-Mini-Batch-梯度下降">15.2 Mini-Batch 梯度下降</h2>
<ul>
<li>
<p>思想：介于batch 梯度下降与随机梯度下降之间，选用b个样本进行梯度下降</p>
</li>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/pkEy7BIJ4qcDNMh.png" alt="image-20220625202421172"></p>
</li>
<li>
<p>Mini-Batch 步骤：</p>
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/Jmkg72IboKPQ4yY.png" alt="image-20220625202623999"></li>
</ul>
</li>
</ul>
<p>​</p>
<h2 id="15-3-随机梯度收敛">15.3 随机梯度收敛</h2>
<ul>
<li>思想：不是每一步进行检验损失函数是否 下降，选择一个步骤间隙，每隔一个大步骤计算损失函数平均值 并检查与前一大步 损失函数是否下降
<ul>
<li><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/ZzYc5FNjvsbtIqR.png" alt="image-20220625204303975"></li>
</ul>
</li>
</ul>
<h2 id="15-4-减少映射与数据并行（Map-Reduce）">15.4 减少映射与数据并行（Map Reduce）</h2>
<ul>
<li>
<p>思想：</p>
<ul>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/CBfcdW7xeSXupNV.png" alt="image-20220625210234644"></p>
</li>
<li>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://s2.loli.net/2022/06/25/T9gICP5pjsJDKya.png" alt="image-20220625210258801"></p>
</li>
</ul>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/VincentVanNF">VincentVan</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://vincentvannf.github.io/2022/07/31/ML/">https://vincentvannf.github.io/2022/07/31/ML/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://vincentvannf.github.io" target="_blank">VincentVan</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Machine-Learning/">Machine Learning</a><a class="post-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=null" async="async"></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/Wechat.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/Wechat.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/ZFB.jpg" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/ZFB.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/08/01/SAP_IBSO_TOOLS_PART3/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/docker_exercise.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">SAP_IBSO_TOOLS_PART3</div></div></a></div><div class="next-post pull-right"><a href="/2022/07/31/SAP_Docker/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/docker.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Docker</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/09/03/Pytorch/" title="Basic DL Using Pytorch"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/pytorch.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-03</div><div class="title">Basic DL Using Pytorch</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">VincentVan</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">21</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">27</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">17</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/VincentVanNF"><i class="fab fa-github"></i><span>Github</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/VincentVanNF" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:3080167665@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">每天睡够8小时</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">监督机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">无监督机器学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">2.线性模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">3.梯度下降法</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">4.多功能线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1%E5%A4%9A%E7%89%B9%E5%BE%81"><span class="toc-number">5.1.</span> <span class="toc-text">4.1多特征</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2%E5%A4%9A%E5%85%83%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="toc-number">5.2.</span> <span class="toc-text">4.2多元梯度下降</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-3%E7%89%B9%E5%BE%81%E7%BC%A9%E6%94%BE"><span class="toc-number">5.3.</span> <span class="toc-text">4.3特征缩放</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-4%E5%AD%A6%E4%B9%A0%E7%8E%87%EF%BC%9A"><span class="toc-number">5.4.</span> <span class="toc-text">4.4学习率：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-5%E7%89%B9%E5%BE%81%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92"><span class="toc-number">5.5.</span> <span class="toc-text">4.5特征与多项式回归</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-6%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B"><span class="toc-number">5.6.</span> <span class="toc-text">4.6正规方程</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">6.</span> <span class="toc-text">5.分类：逻辑回归算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1-%E4%BA%8C%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98"><span class="toc-number">6.1.</span> <span class="toc-text">5.1 二分类问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-2-%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98"><span class="toc-number">6.2.</span> <span class="toc-text">5.2 多分类问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-1%E4%B8%80%E5%AF%B9%E5%A4%9A"><span class="toc-number">6.2.1.</span> <span class="toc-text">5.2.1一对多</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-3-%E8%BF%87%E6%8B%9F%E5%90%88"><span class="toc-number">6.3.</span> <span class="toc-text">5.3 过拟合</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-1%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">6.3.1.</span> <span class="toc-text">5.3.1线性回归正则化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-2-logical%E5%9B%9E%E5%BD%92%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">6.3.2.</span> <span class="toc-text">5.3.2 logical回归正则化</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">7.</span> <span class="toc-text">6 神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#6-1-%E6%A8%A1%E5%9E%8B%E5%B1%95%E7%A4%BA"><span class="toc-number">7.1.</span> <span class="toc-text">6.1 模型展示</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-2-%E6%A8%A1%E5%9E%8B%E5%B1%95%E7%A4%BA"><span class="toc-number">7.2.</span> <span class="toc-text">6.2 模型展示</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-3%E4%BE%8B%E5%AD%90%E4%B8%8E%E7%9B%B4%E8%A7%89%E8%A7%A3%E9%87%8A"><span class="toc-number">7.3.</span> <span class="toc-text">6.3例子与直觉解释</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-4%E5%A4%9A%E5%85%83%E5%88%86%E7%B1%BB"><span class="toc-number">7.4.</span> <span class="toc-text">6.4多元分类</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">8.</span> <span class="toc-text">7 神经网络原理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#7-1-%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0"><span class="toc-number">8.1.</span> <span class="toc-text">7.1 代价函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-2-%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95"><span class="toc-number">8.2.</span> <span class="toc-text">7.2 反向传播算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-3-%E6%A2%AF%E5%BA%A6%E6%A3%80%E6%B5%8B"><span class="toc-number">8.3.</span> <span class="toc-text">7.3 梯度检测</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-4-%E9%9A%8F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">8.4.</span> <span class="toc-text">7.4 随机初始化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-5-%E6%80%BB%E7%BB%93"><span class="toc-number">8.5.</span> <span class="toc-text">7.5 总结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">9.</span> <span class="toc-text">8 机器学习算法诊断</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#8-1-%E8%AF%84%E4%BC%B0%E5%81%87%E8%AE%BE"><span class="toc-number">9.1.</span> <span class="toc-text">8.1 评估假设</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-2-%E6%A8%A1%E5%9E%8B-%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%EF%BC%8C%E8%AE%AD%E7%BB%83%EF%BC%8C%E9%AA%8C%E8%AF%81%EF%BC%8C%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">9.2.</span> <span class="toc-text">8.2 模型&#x2F;特征选择，训练，验证，测试数据集</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-3-%E8%AF%8A%E6%96%AD%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE"><span class="toc-number">9.3.</span> <span class="toc-text">8.3 诊断偏差与方差</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-4-%E6%AD%A3%E5%88%99%E5%8C%96%E4%B8%8E%E5%81%8F%E5%B7%AE%EF%BC%8C%E6%96%B9%E5%B7%AE"><span class="toc-number">9.4.</span> <span class="toc-text">8.4 正则化与偏差，方差</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-5-%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF"><span class="toc-number">9.5.</span> <span class="toc-text">8.5 学习曲线</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">10.</span> <span class="toc-text">9 机器学习系统设计思想</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#9-1%E4%B8%8D%E5%AF%B9%E7%A7%B0%E5%88%86%E7%B1%BB%E8%AF%AF%E5%B7%AE%E8%AF%84%E4%BC%B0"><span class="toc-number">10.1.</span> <span class="toc-text">9.1不对称分类误差评估</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">11.</span> <span class="toc-text">10 支持向量机 SVM</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#10-1%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87"><span class="toc-number">11.1.</span> <span class="toc-text">10.1优化目标</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-2-%E5%A4%A7%E9%97%B4%E8%B7%9D%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">11.2.</span> <span class="toc-text">10.2 大间距分类器</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#10-3-%E6%A0%B8%E5%87%BD%E6%95%B0"><span class="toc-number">11.3.</span> <span class="toc-text">10.3 核函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8SVM"><span class="toc-number">11.4.</span> <span class="toc-text">使用SVM</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">12.</span> <span class="toc-text">11 无监督学习</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#11-1-K-Means-%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="toc-number">12.1.</span> <span class="toc-text">11.1 K-Means 聚类算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-2-%E4%BC%98%E5%8C%96%E7%9B%AE%E6%A0%87"><span class="toc-number">12.2.</span> <span class="toc-text">11.2 优化目标</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-3%E9%9A%8F%E6%9C%BA%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">12.3.</span> <span class="toc-text">11.3随机初始化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#11-4-%E9%80%89%E5%8F%96%E8%81%9A%E7%B1%BB%E6%95%B0%E9%87%8F"><span class="toc-number">12.4.</span> <span class="toc-text">11.4 选取聚类数量</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">13.</span> <span class="toc-text">12 降维</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#12-1-%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9"><span class="toc-number">13.1.</span> <span class="toc-text">12.1 数据压缩</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-2-%E4%B8%BB%E6%88%90%E5%88%86%E6%9E%90%E9%97%AE%E9%A2%98%E8%A7%84%E5%88%92-PCA"><span class="toc-number">13.2.</span> <span class="toc-text">12.2 主成分析问题规划 PCA</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-3-%E5%8E%8B%E7%BC%A9%E9%87%8D%E7%8E%B0"><span class="toc-number">13.3.</span> <span class="toc-text">12.3 压缩重现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-4%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9K"><span class="toc-number">13.4.</span> <span class="toc-text">12.4如何选择K</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#12-5-PCA%E4%BD%BF%E7%94%A8%E5%BB%BA%E8%AE%AE"><span class="toc-number">13.5.</span> <span class="toc-text">12.5 PCA使用建议</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">14.</span> <span class="toc-text">13 异常检测</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#13-1-%E9%97%AE%E9%A2%98%E5%8A%A8%E6%9C%BA"><span class="toc-number">14.1.</span> <span class="toc-text">13.1 问题动机</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-2-%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%EF%BC%88%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%EF%BC%89"><span class="toc-number">14.2.</span> <span class="toc-text">13.2 高斯分布（正态分布）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-3-%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95"><span class="toc-number">14.3.</span> <span class="toc-text">13.3 异常检测算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-4-%E8%AF%84%E4%BC%B0-%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95"><span class="toc-number">14.4.</span> <span class="toc-text">13.4 评估 异常检测算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-5-%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E4%B8%8E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-number">14.5.</span> <span class="toc-text">13.5  异常检测与监督学习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-6-%E5%A6%82%E4%BD%95-%E9%80%89%E6%8B%A9-%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B-%E7%89%B9%E5%BE%81"><span class="toc-number">14.6.</span> <span class="toc-text">13.6 如何 选择 异常检测 特征</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#13-7-%E5%A4%9A%E5%8F%98%E9%87%8F%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83"><span class="toc-number">14.7.</span> <span class="toc-text">13.7 多变量高斯分布</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">15.</span> <span class="toc-text">14 推荐算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#14-1-%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95"><span class="toc-number">15.1.</span> <span class="toc-text">14.1 基于内容的推荐算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#14-2-%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4"><span class="toc-number">15.2.</span> <span class="toc-text">14.2 协同过滤</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#14-3-%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E5%90%91%E9%87%8F%E5%8C%96"><span class="toc-number">15.3.</span> <span class="toc-text">14.3 协同过滤向量化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#14-4-%E5%9D%87%E5%80%BC%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-number">15.4.</span> <span class="toc-text">14.4 均值归一化</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">16.</span> <span class="toc-text">15 大数据机器学习处理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#15-1-%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="toc-number">16.1.</span> <span class="toc-text">15.1 随机梯度下降</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#15-2-Mini-Batch-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="toc-number">16.2.</span> <span class="toc-text">15.2 Mini-Batch 梯度下降</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#15-3-%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E6%94%B6%E6%95%9B"><span class="toc-number">16.3.</span> <span class="toc-text">15.3 随机梯度收敛</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#15-4-%E5%87%8F%E5%B0%91%E6%98%A0%E5%B0%84%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%EF%BC%88Map-Reduce%EF%BC%89"><span class="toc-number">16.4.</span> <span class="toc-text">15.4 减少映射与数据并行（Map Reduce）</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/09/03/Pytorch/" title="Basic DL Using Pytorch"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/pytorch.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Basic DL Using Pytorch"/></a><div class="content"><a class="title" href="/2022/09/03/Pytorch/" title="Basic DL Using Pytorch">Basic DL Using Pytorch</a><time datetime="2022-09-02T16:50:00.000Z" title="发表于 2022-09-03 00:50:00">2022-09-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/01/SAP_Dynatrace/" title="SAP_Dynatrace"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/Dynatrace.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SAP_Dynatrace"/></a><div class="content"><a class="title" href="/2022/08/01/SAP_Dynatrace/" title="SAP_Dynatrace">SAP_Dynatrace</a><time datetime="2022-08-01T07:00:00.000Z" title="发表于 2022-08-01 15:00:00">2022-08-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/01/SAP_Git/" title="SAP_Git"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/git.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SAP_Git"/></a><div class="content"><a class="title" href="/2022/08/01/SAP_Git/" title="SAP_Git">SAP_Git</a><time datetime="2022-08-01T07:00:00.000Z" title="发表于 2022-08-01 15:00:00">2022-08-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/01/SAP_IBSO_TOOLS_PART2/" title="SAP_IBSO_TOOLS_PART2"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/exercise1_5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SAP_IBSO_TOOLS_PART2"/></a><div class="content"><a class="title" href="/2022/08/01/SAP_IBSO_TOOLS_PART2/" title="SAP_IBSO_TOOLS_PART2">SAP_IBSO_TOOLS_PART2</a><time datetime="2022-08-01T07:00:00.000Z" title="发表于 2022-08-01 15:00:00">2022-08-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/01/SAP_IBSO_TOOLS_PART1/" title="SAP_IBSO_TOOLS_PART1"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/IBSO.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SAP_IBSO_TOOLS_PART1"/></a><div class="content"><a class="title" href="/2022/08/01/SAP_IBSO_TOOLS_PART1/" title="SAP_IBSO_TOOLS_PART1">SAP_IBSO_TOOLS_PART1</a><time datetime="2022-08-01T07:00:00.000Z" title="发表于 2022-08-01 15:00:00">2022-08-01</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright"><div><b><font color="#00BFFF">&copy;2021 - 2023 By </font></b> <b><a font color="#00BFFF"href=https://vincentvannf.github.io/ style="position: relative; z-index: 10"><font color="#00BFFF">VincentVan</a></font></b></div></div><div class="footer_custom_text"><b><font color="#00BFFF">Hi, Welcom to my blog.</font></b></div></div><div id="footer-wrap" style="iposition:absolute;text-align:cente;inset:20px;"></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-info"><div class="algolia-stats"></div><div class="algolia-poweredBy"></div></div></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="https://cdn.jsdelivr.net/npm/algoliasearch/dist/algoliasearch-lite.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instantsearch.js/dist/instantsearch.production.min.js"></script><script src="/js/search/algolia.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const $mermaidWrap = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaidWrap.length) {
    window.runMermaid = () => {
      window.loadMermaid = true
      const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

      Array.from($mermaidWrap).forEach((item, index) => {
        const mermaidSrc = item.firstElementChild
        const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
        const mermaidID = 'mermaid-' + index
        const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent
        mermaid.mermaidAPI.render(mermaidID, mermaidDefinition, (svgCode) => {
          mermaidSrc.insertAdjacentHTML('afterend', svgCode)
        })
      })
    }

    const loadMermaid = () => {
      window.loadMermaid ? runMermaid() : getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaid)
    }

    window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
  }
})()</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: '8f42e6f2019939020945',
      clientSecret: 'e8db6e1f9cc7b4ec40ba8ce4d76250264b125b8c',
      repo: 'VincentVanNF.github.io',
      owner: 'VincentVanNF',
      admin: ['VincentVanNF'],
      id: '9a16c67c587e1a4b7cd41dbce3547469',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const findTrueUrl = (array) => {
    Promise.all(array.map(item =>
      fetch(item.url).then(resp => resp.json()).then(data => {
        const urlArray = data.body.match(/(https?:\/\/)?([\da-z\.-]+)\.([a-z\.]{2,6})([\/\w \.-]*)*\/?/ig)
        if (data.user.login === 'utterances-bot') {
          return urlArray.pop()
        } else {
          return urlArray.shift()
        }
      })
    )).then(res => {
        array = array.map((i,index)=> {
          return {
            ...i,
            url: res[index]
          }
        })

        saveToLocal.set('github-newest-comments', JSON.stringify(array), 10/(60*24))
        generateHtml(array)
    });
  }

  const getComment = () => {
    fetch('https://api.github.com/repos/VincentVanNF/VincentVanNF.github.io/issues/comments?sort=updated&direction=desc&per_page=6&page=1',{
      "headers": {
        Accept: 'application/vnd.github.v3.html+json'
      }
    })
      .then(response => response.json())
      .then(data => {
        const githubArray = data.map(item => {
          return {
            'avatar': item.user.avatar_url,
            'content': changeContent(item.body_html),
            'nick': item.user.login,
            'url': item.issue_url,
            'date': item.updated_at,
            'githubUrl': item.html_url
          }
        })
        findTrueUrl(githubArray)
      }).catch(e => {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.innerHTML= "无法获取评论，请确认相关配置是否正确"
      })
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }

        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('github-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><div class="aplayer no-destroy" data-id="7622286806" data-server="netease" data-type="playlist" data-fixed="true" data-mutex="true" data-autoplay="false" > </div><script src="/js/jquery.min.js"></script><script src="/js/fishes.js"></script><canvas class="fireworks" mobile="true"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/fireworks.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script>(function(d, w, c) {
    w.ChatraID = 'xKZME3aZENuKqB3Z7';
    var s = d.createElement('script');
    w[c] = w[c] || function() {
        (w[c].q = w[c].q || []).push(arguments);
    };
    s.async = true;
    s.src = 'https://call.chatra.io/chatra.js';
    if (d.head) d.head.appendChild(s);
})(document, window, 'Chatra');

if (false) {
  var chatBtnFn = () => {
    var chatBtn = document.getElementById("chat_btn")
    chatBtn.addEventListener("click", function(){
      Chatra('openChat')
    });
  }
  chatBtnFn()
} else {
  if (false) {
    function chatBtnHide () {
      Chatra('hide')
    }
    function chatBtnShow () {
      Chatra('show')
    }
  }
}</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"]):not([href="/music/"]):not([href="/no-pjax/"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: true,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', 'UA-239901416-2', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v5.4.0" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly_v4.4.0" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://www.jsdelivr.com/" style="margin-inline:5px" data-title="本站使用JsDelivr为静态资源提供CDN加速" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&amp;logo=jsDelivr" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></p>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script async src="/js/runtime.js"></script><!-- hexo injector body_end end --></body></html>